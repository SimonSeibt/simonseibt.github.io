---
layout: post
title: HHTS (Paper@CVPR2024)
date: 2024-06-05 12:10:00-0400
description: Project overview
tags: Oversegmentation Superpixel Histogram ImageProcessing
categories:
giscus_comments: false
related_posts: false
related_publications: 
thumbnail: assets/img/cvpr/cvpr_logo.jpg
change_title: true
header_title: Hierarchical Histogram Threshold Segmentation - Auto-terminating High-detail Oversegmentation
change_keywords: true
paper_keywords: CVPR, Oversegmentation, Superpixel, Histogram, ImageProcessing, Research
---

<iframe id="hhtsIframe" src="https://changtvs.github.io/hierarchical-histogram-threshold-segmentation/" frameborder="0" scrolling="no" style="overflow:hidden; height:4000px; width:100%;" height="100%" width="100%"></iframe>
<meta name="description" content="Superpixels play a crucial role in image processing by partitioning an image into clusters of pixels with similar visual attributes. This facilitates subsequent image processing tasks, offering computational advantages over the manipulation of individual pixels. While numerous oversegmentation techniques have emerged in recent years, many rely on predefined initialization and termination criteria. In this paper, a novel top-down superpixel segmentation algorithm called Hierarchical Histogram Threshold Segmentation (HHTS) is introduced. It eliminates the need for initialization and implements auto-termination, outperforming state-of-the-art methods w.r.t. boundary recall. This is achieved by iteratively partitioning individual pixel segments into foreground and background and applying intensity thresholding across multiple color channels. The underlying iterative process constructs a superpixel hierarchy that adapts to local detail distributions until color information exhaustion. Experimental results demonstrate the superiority of the proposed approach in terms of boundary adherence, while maintaining competitive runtime performance on the BSDS500 and NYUV2 datasets. Furthermore, an application of HHTS in refining machine learning-based semantic segmentation masks produced by the Segment Anything Foundation Model (SAM) is presented.">