---
layout: post
title: DFM4SfM (Paper@ICIP2023)
date: 2023-12-10 12:10:00-0400
description: Project overview
tags: ImageProcessing StructureFromMotion FeatureMatching 3D-Reconstruction
categories:
giscus_comments: false
related_posts: false
related_publications: 
thumbnail: assets/img/dfm4sfm/icip_logo.png
---
<hr>
<style>
table, td, th {
   border: none!important;
}
</style>

<center><h1><b>DFM4SfM</b><br></h1><h2><b>Dense Feature Matching for Structure from Motion</b></h2></center>
<br>
<center><h3>ICIP'2023</h3></center>
<br>
<center><h6>Simon Seibt<sup>1</sup>, Bartosz von Rymon Lipinski<sup>1</sup>, Thomas Chang<sup>1</sup> and Marc Erich Latoschik<sup>2</sup></h6></center>
<br>
<center><sup>1</sup> Game Tech Lab, Nuremberg Institute of Technology<br>
<sup>2</sup> Human-Computer Interaction Group, University of Wuerzburgy</center>
<br>
<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <div class="text-center">
            {% include figure.html path="assets/img/dfm4sfm/cover.png" class="img-fluid rounded z-depth-1" width=700 zoomable=true %}
            <center><p>DFM4SfM result of the scene "Church" (Tanks and Temples dataset [1])</p></center>
        </div>
    </div>
</div>
<br>
<center><h3><b>Abstract</b></h3></center>
<p style="text-align: justify;">Structure from motion (SfM) is a fundamental task in computer vision and allows recovering the 3D structure of a stationary scene from an image set. Finding robust and accurate feature matches plays a crucial role in the early stages of SfM. So in this work, we propose a novel method for computing image correspondences based on dense feature matching (DFM) using homographic decomposition: The underlying pipeline provides refinement of existing matches through iterative rematching, detection of occlusions and extrapolation of additional matches in critical image areas between image pairs. Our main contributions are improvements of DFM specifically for SfM, resulting in global refinement and global extrapolation of image correspondences between related views. Furthermore, we propose an iterative version of the Delaunay-triangulation-based outlier detection algorithm for robust processing of repeated image patterns. Through experiments, we demonstrate that the proposed method significantly improves the reconstruction accuracy.</p>
<br>
<center><h3><b>Paper</b></h3></center>
<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <div class="text-center">
            <a href="https://ieeexplore.ieee.org/document/10328368">{% include figure.html path="assets/img/dfm4sfm/paper_cover.png" width="280" zoomable=false %}</a>
        </div>
    </div>
</div>
<br>
<center><h3><b>Pipeline Overview</b></h3></center>
<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <div class="text-center">
            {% include figure.html path="assets/img/dfm4sfm/pipeline-overview.jpg" width="700" zoomable=true %}
            <center><p>UML activity diagram of the DFM4SfM pipeline, integrated into a SfM pipeline</p></center>
        </div>
    </div>
</div>
<br>
<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <div class="text-center">
            {% include figure.html path="assets/img/dfm4sfm/DFM.gif" class="img-fluid rounded z-depth-1" zoomable=true %}
            <center><p>Dense Feature Matching based on Homographic Decomposition</p></center>
        </div>
    </div>
        <div class="col-sm mt-3 mt-md-0">
        <div class="text-center">
            {% include figure.html path="assets/img/dfm4sfm/GR.jpg" class="img-fluid rounded z-depth-1" zoomable=true %}
            <center><p>Global Refinement: Extension of positional refinement to a multi-view approach</p></center>
        </div>
    </div>
        <div class="col-sm mt-3 mt-md-0">
        <div class="text-center">
            {% include figure.html path="assets/img/dfm4sfm/GE.jpg" class="img-fluid rounded z-depth-1" zoomable=true %}
            <center><p>Global Extrapolation: Mutual extrapolation of feature matches by considering multiple adjacent views</p></center>
        </div>
    </div>
</div>
<br>
<center><h3><b>Visual Results</b></h3></center>
<center>Comparison of the built-in feature matching approaches in COLMAP [2] and OpenMVG [3] with our DFM4SfM approach. A fixed ”test keypoint set” was initially detected.</center>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
    <div class="text-center">
        <center><p><b>Scene: Castle (DMVS dataset [4])</b></p></center>
         {% include video.html path="assets/video/colmap_castle.mp4" class="img-fluid rounded z-depth-1" width=700 controls=true autoplay=false loop=true %}     
    </div>
    </div>
</div>
<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
    <div class="text-center">
        <center><p><b>Scene: Facade (ETH3D dataset [5])</b></p></center>
        {% include video.html path="assets/video/colmap_facade.mp4" class="img-fluid rounded z-depth-1" width=700 controls=true autoplay=false loop=true %}  
    </div>
    </div>
</div>
<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
    <div class="text-center">
        <center><p><b>Scene: Terrains (ETH3D dataset [5])</b></p></center>
        {% include video.html path="assets/video/openmvg_terrains.mp4" class="img-fluid rounded z-depth-1" width=700 controls=true autoplay=false loop=true %}    
    </div>
    </div>
</div>
<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
    <div class="text-center">
        <center><p><b>Scene: Courtyard (ETH3D dataset [5])</b></p></center>
         {% include video.html path="assets/video/openmvg_courtyard.mp4" class="img-fluid rounded z-depth-1" width=700 controls=true autoplay=false loop=true %}    
    </div>
    </div>
</div>
<br>
<h3><b>BibTeX</b></h3>
>@inproceedings{Seibt2023DFM4SfM,<br>
>  author = {Seibt, Simon and Von Rymon Lipinski, Bartosz and Chang, Thomas and Latoschik, Marc Erich},<br>
>  title = {DFM4SfM - Dense Feature Matching for Structure from Motion},<br>
>  booktitle = {IEEE International Conference on Image Processing Workshops},<br>
>  year = {2023},<br>
>}
{: .block-tip }
<br>
References

| :---| :------------------------------------------------------------------------------- | 
| [1] | A. Knapitsch, J. Park, Q.-Y. Zhou, and V. Koltun, “Tanks and temples: Benchmarking large-scale scene reconstruction,” ACM Trans. on Graph., 2017.|
| [2] | J. L. Schoenberger and J.-M. Frahm, “Structure-from-motion revisited,” in Proc. IEEE Conf. Comput. Vis. Pattern Recognit., 2016.|
| [3] | P. Moulon, P. Monasse, R. Perrot, and R. Marlet, “Open-MVG: Open multiple view geometry,” in Int. Workshop on Reprod. Res. in Patt. Recogn., 2016, pp. 60–74.|
| [4] | C. Strecha, W. von Hansen, L. Van Gool, P. Fua, and U. Thoennessen, “On benchmarking camera calibration and multi-view stereo for high resolution imagery,” in Proc. IEEE Conf. Comput. Vis. Pattern Recognit., 2008.|
| [5] | T. Schöps, T. Sattler, and M. Pollefeys, “BAD SLAM: Bundle adjusted direct,” in Proc. IEEE Conf. Comput. Vis. Pattern Recognit., 2019.|